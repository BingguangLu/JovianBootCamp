{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression\n",
    "## Problem\n",
    "Given a dataset, predict if it will rain tomorrow.\n",
    "1. This is a classification problem.\n",
    "2. If want to use regression, then the response variable need to be a numeric value.\n",
    "3. One way to do it is to consider the probability of rain tomorrow as a dependent variable.\n",
    "4. However this will result the predicted probability of the model can be greater than 1 or less than 0.\n",
    "5. Hence, use odds ratio as dependent variable. (Logistic Regression)\n",
    "\n",
    "## Linear Regression v.s. Logistic Regression\n",
    "Logistic Regression is fit for classification problem.\n",
    "### Classifiaction Problem\n",
    "Assign input into classes, but in dataset have the 'true' classification (hence supervised)\n",
    "Use logistic regression to solve classifiaction problems.\n",
    "- Take linear convination\n",
    "- Apply sigmoid function to the result so that the output in between 0 and 1\n",
    "- Cross entropy as loss function\n",
    "### Regression Problem\n",
    "Assign input to get a continuous value.\n",
    "Use linear regression to solve regression problems.\n",
    "\n",
    "## ML Workflow\n",
    "1. initialize model\n",
    "2. pass input into model to obtain predictions\n",
    "3. compare predictions with actual targets with loss function\n",
    "4. optimization\n",
    "5. repeat until model is considered to be good enough\n",
    "\n",
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# !pip install opendatasets --upgrade --quiet\n",
    "import opendatasets as od"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weather-dataset-rattle-package.zip to .\\weather-dataset-rattle-package\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.83M/3.83M [00:00<00:00, 20.8MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_url = 'https://www.kaggle.com/jsphyg/weather-dataset-rattle-package'\n",
    "od.download(dataset_url)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To see the data in Data folder:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['medical.csv', 'weatherAUS.csv']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('Data')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To load the data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('Data/weatherAUS.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check demsion and basic info of the dataset:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "See that some of the column has null value, RainTomorrow need to be treated carefully as it is the thing we want to predict. It is not a good solution to fill in the missing value in this field, better solution is to consider null value as own class or just simply delete null. Similar for RainToday value as it is very likely to be very close related with the response."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "raw_df.dropna(subset=['RainToday', 'RainTomorrow'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For other missing values, have many ways:\n",
    "- Can fill in the average if the feature is normally distributed\n",
    "- Can delete null if null value is not many\n",
    "- Can check the correlation and simply don't include that feature in the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Analysis and Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
    "matplotlib.rcParams['figure.facecolor'] = '#00000000'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.histogram(raw_df, x='Location', title='Location v.s. Rainy Days', color='RainToday')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.histogram(raw_df, x='Temp3pm', title='Temperature at 3 pm vs. Rain Tomorrow', color='RainTomorrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.histogram(raw_df, x='RainTomorrow', color='RainToday', title='Rain Tomorrow vs. Rain Today')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.scatter(raw_df.sample(2000), title='Temp (3 pm) vs. Humidity (3 pm)', x='Temp3pm', y='Humidity3pm',\n",
    "           color='RainTomorrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Location follows a uniform distribution, Temp3pm follow a normal distribution, and RainTomorrow seems strongly correlated with Location, Temp3pm, and RainToday. However, Humidity 3pm seems positively correlated with RainTomorrow."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.histogram(raw_df, x='Date', title='RainTomorrow v.s. Date', color='RainToday')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "See that not strongly correlated with Date."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.scatter(raw_df.sample(2000), title='MinTemp vs. MaxTemp', x='MinTemp', y='MaxTemp',\n",
    "           color='RainTomorrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "See that if RainTomorrow, Max Temp tend to be lower."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.histogram(raw_df, x='Rainfall', title='RainTomorrow v.s. Rainfall', color='RainToday')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems that Rainfall can be used, but need to take further calculation as the plot is squeezed very much around 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.histogram(raw_df, x='Evaporation', title='Evaporation v.s. Rain Tomorrow', color='RainToday')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.histogram(raw_df, x='Sunshine', title='Sunshine v.s. Rain Tomorrow', color='RainToday')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sunshine are expected to have high correlation with the dependent value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.violinplot(data=raw_df, x='Sunshine', y='RainTomorrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.violinplot(data=raw_df, x='WindSpeed9am', y='RainTomorrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.violinplot(data=raw_df, x='WindSpeed3pm', y='RainTomorrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.histogram(raw_df, x='WindDir9am', title='WindDir v.s. Rain Tomorrow', color='RainToday')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.histogram(raw_df, x='WindDir3pm', title='WindDir v.s. Rain Tomorrow', color='RainToday')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.scatter(raw_df.sample(2000), title='Humidity', x='Humidity9am', y='Humidity3pm',\n",
    "           color='RainTomorrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems Humidity at any time can have reasonable strong correlation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.scatter(raw_df.sample(2000), title='Pressure', x='Pressure9am', y='Pressure3pm',\n",
    "           color='RainTomorrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.violinplot(data=raw_df, x='Cloud9am', y='RainTomorrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.violinplot(data=raw_df, x='Cloud3pm', y='RainTomorrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems cloud also have high correlation to the prediction.\n",
    "## Working with a Sample"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "use_sample = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "sample_fraction = 0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "if use_sample:\n",
    "    raw_df = raw_df.sample(frac=sample_fraction).copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training, Validation and Test Sets\n",
    "- Training set: to train the model\n",
    "- Validation set: to evaluate the model during the training\n",
    "- Test set: to test the model after training to see if model overfit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "training_val_df, testing_df = train_test_split(raw_df, test_size=0.2, random_state=42)\n",
    "training_df, val_df = train_test_split(training_val_df, test_size=0.25, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If deal with dates, it's often better idea to separate the training, validation and test sets with time, so model can train on data former to the testing data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "year = pd.to_datetime(raw_df.Date).dt.year\n",
    "\n",
    "training_df = raw_df[year < 2015]\n",
    "val_df = raw_df[year == 2015]\n",
    "testing_df = raw_df[year > 2015]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Filtering\n",
    "For example, as stated above, Date column can be ignored"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "x_col = list(training_df.columns)[1:-1]\n",
    "y_col = 'RainTomorrow'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "training_x = training_df[x_col].copy()\n",
    "training_y = training_df[y_col].copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "validating_x = val_df[x_col].copy()\n",
    "validating_y = val_df[y_col].copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "testing_x = testing_df[x_col].copy()\n",
    "testing_y = testing_df[y_col].copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Determine if the columns are numerical or categorical:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "numeric_cols = training_x.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = training_x.select_dtypes('object').columns.tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "            MinTemp       MaxTemp      Rainfall   Evaporation      Sunshine  \\\ncount  97674.000000  97801.000000  97988.000000  61657.000000  57942.000000   \nmean      12.007831     23.022202      2.372935      5.289991      7.609004   \nstd        6.347175      6.984397      8.518819      3.952010      3.788813   \nmin       -8.500000     -4.100000      0.000000      0.000000      0.000000   \n25%        7.500000     17.900000      0.000000      2.600000      4.800000   \n50%       11.800000     22.400000      0.000000      4.600000      8.500000   \n75%       16.600000     27.900000      0.800000      7.200000     10.600000   \nmax       33.900000     48.100000    371.000000     82.400000     14.300000   \n\n       WindGustSpeed  WindSpeed9am  WindSpeed3pm   Humidity9am   Humidity3pm  \\\ncount   91160.000000  97114.000000  96919.000000  96936.000000  96872.000000   \nmean       40.215873     14.092263     18.764608     68.628745     51.469547   \nstd        13.697967      8.984203      8.872398     19.003097     20.756113   \nmin         6.000000      0.000000      0.000000      0.000000      0.000000   \n25%        31.000000      7.000000     13.000000     57.000000     37.000000   \n50%        39.000000     13.000000     19.000000     70.000000     52.000000   \n75%        48.000000     19.000000     24.000000     83.000000     66.000000   \nmax       135.000000     87.000000     87.000000    100.000000    100.000000   \n\n        Pressure9am   Pressure3pm      Cloud9am      Cloud3pm       Temp9am  \\\ncount  88876.000000  88857.000000  63000.000000  61966.000000  97414.000000   \nmean    1017.513734   1015.132352      4.302952      4.410677     16.835126   \nstd        7.072510      6.997072      2.866634      2.693370      6.404586   \nmin      980.500000    979.000000      0.000000      0.000000     -5.900000   \n25%     1012.800000   1010.400000      1.000000      2.000000     12.200000   \n50%     1017.500000   1015.100000      5.000000      5.000000     16.600000   \n75%     1022.300000   1019.900000      7.000000      7.000000     21.400000   \nmax     1041.000000   1039.600000      9.000000      9.000000     40.200000   \n\n            Temp3pm  \ncount  97392.000000  \nmean      21.540138  \nstd        6.831612  \nmin       -5.100000  \n25%       16.600000  \n50%       20.900000  \n75%       26.200000  \nmax       46.100000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustSpeed</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>97674.000000</td>\n      <td>97801.000000</td>\n      <td>97988.000000</td>\n      <td>61657.000000</td>\n      <td>57942.000000</td>\n      <td>91160.000000</td>\n      <td>97114.000000</td>\n      <td>96919.000000</td>\n      <td>96936.000000</td>\n      <td>96872.000000</td>\n      <td>88876.000000</td>\n      <td>88857.000000</td>\n      <td>63000.000000</td>\n      <td>61966.000000</td>\n      <td>97414.000000</td>\n      <td>97392.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>12.007831</td>\n      <td>23.022202</td>\n      <td>2.372935</td>\n      <td>5.289991</td>\n      <td>7.609004</td>\n      <td>40.215873</td>\n      <td>14.092263</td>\n      <td>18.764608</td>\n      <td>68.628745</td>\n      <td>51.469547</td>\n      <td>1017.513734</td>\n      <td>1015.132352</td>\n      <td>4.302952</td>\n      <td>4.410677</td>\n      <td>16.835126</td>\n      <td>21.540138</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>6.347175</td>\n      <td>6.984397</td>\n      <td>8.518819</td>\n      <td>3.952010</td>\n      <td>3.788813</td>\n      <td>13.697967</td>\n      <td>8.984203</td>\n      <td>8.872398</td>\n      <td>19.003097</td>\n      <td>20.756113</td>\n      <td>7.072510</td>\n      <td>6.997072</td>\n      <td>2.866634</td>\n      <td>2.693370</td>\n      <td>6.404586</td>\n      <td>6.831612</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-8.500000</td>\n      <td>-4.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>980.500000</td>\n      <td>979.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-5.900000</td>\n      <td>-5.100000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>7.500000</td>\n      <td>17.900000</td>\n      <td>0.000000</td>\n      <td>2.600000</td>\n      <td>4.800000</td>\n      <td>31.000000</td>\n      <td>7.000000</td>\n      <td>13.000000</td>\n      <td>57.000000</td>\n      <td>37.000000</td>\n      <td>1012.800000</td>\n      <td>1010.400000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>12.200000</td>\n      <td>16.600000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>11.800000</td>\n      <td>22.400000</td>\n      <td>0.000000</td>\n      <td>4.600000</td>\n      <td>8.500000</td>\n      <td>39.000000</td>\n      <td>13.000000</td>\n      <td>19.000000</td>\n      <td>70.000000</td>\n      <td>52.000000</td>\n      <td>1017.500000</td>\n      <td>1015.100000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>16.600000</td>\n      <td>20.900000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>16.600000</td>\n      <td>27.900000</td>\n      <td>0.800000</td>\n      <td>7.200000</td>\n      <td>10.600000</td>\n      <td>48.000000</td>\n      <td>19.000000</td>\n      <td>24.000000</td>\n      <td>83.000000</td>\n      <td>66.000000</td>\n      <td>1022.300000</td>\n      <td>1019.900000</td>\n      <td>7.000000</td>\n      <td>7.000000</td>\n      <td>21.400000</td>\n      <td>26.200000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>33.900000</td>\n      <td>48.100000</td>\n      <td>371.000000</td>\n      <td>82.400000</td>\n      <td>14.300000</td>\n      <td>135.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>1041.000000</td>\n      <td>1039.600000</td>\n      <td>9.000000</td>\n      <td>9.000000</td>\n      <td>40.200000</td>\n      <td>46.100000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_x[numeric_cols].describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "Location       49\nWindGustDir    16\nWindDir9am     16\nWindDir3pm     16\nRainToday       2\ndtype: int64"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_x[categorical_cols].nunique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Missing Values\n",
    "One way to deal with the missing value is to filling them.\n",
    "Here use the basic one: fill with average value:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy = 'mean')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "MinTemp            468\nMaxTemp            307\nRainfall             0\nEvaporation      59694\nSunshine         66805\nWindGustSpeed     9105\nWindSpeed9am      1055\nWindSpeed3pm      2531\nHumidity9am       1517\nHumidity3pm       3501\nPressure9am      13743\nPressure3pm      13769\nCloud9am         52625\nCloud3pm         56094\nTemp9am            656\nTemp3pm           2624\ndtype: int64"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[numeric_cols].isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "SimpleImputer()"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit(raw_df[numeric_cols])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "training_x[numeric_cols] = imputer.transform(training_x[numeric_cols])\n",
    "validating_x[numeric_cols] = imputer.transform(validating_x[numeric_cols])\n",
    "testing_x[numeric_cols] = imputer.transform(testing_x[numeric_cols])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "MinTemp          0\nMaxTemp          0\nRainfall         0\nEvaporation      0\nSunshine         0\nWindGustSpeed    0\nWindSpeed9am     0\nWindSpeed3pm     0\nHumidity9am      0\nHumidity3pm      0\nPressure9am      0\nPressure3pm      0\nCloud9am         0\nCloud3pm         0\nTemp9am          0\nTemp3pm          0\ndtype: int64"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "training_x[numeric_cols].isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scaling Numeric Features\n",
    "As stated in Linear Regression, it is often better to scale the numeric features:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "MinMaxScaler()"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(raw_df[numeric_cols])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: [-8.5, -4.8, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 980.5, 977.1, 0.0, 0.0, -7.2, -5.4]\n",
      "Maximum: [33.9, 48.1, 371.0, 145.0, 14.5, 135.0, 130.0, 87.0, 100.0, 100.0, 1041.0, 1039.6, 9.0, 9.0, 40.2, 46.7]\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print(f'Minimum: {list(scaler.data_min_)}\\nMaximum: {list(scaler.data_max_)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Repeat this on train/validation/test dataset:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "training_x[numeric_cols] = scaler.transform(training_x[numeric_cols])\n",
    "validating_x[numeric_cols] = scaler.transform(validating_x[numeric_cols])\n",
    "testing_x[numeric_cols] = scaler.transform(testing_x[numeric_cols])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "            MinTemp       MaxTemp      Rainfall   Evaporation      Sunshine  \\\ncount  97988.000000  97988.000000  97988.000000  97988.000000  97988.000000   \nmean       0.483689      0.525947      0.006396      0.036949      0.525366   \nstd        0.149458      0.131904      0.022962      0.021628      0.200931   \nmin        0.000000      0.013233      0.000000      0.000000      0.000000   \n25%        0.377358      0.429112      0.000000      0.026207      0.517241   \n50%        0.478774      0.514178      0.000000      0.037741      0.526244   \n75%        0.591981      0.618147      0.002156      0.038621      0.634483   \nmax        1.000000      1.000000      1.000000      0.568276      0.986207   \n\n       WindGustSpeed  WindSpeed9am  WindSpeed3pm   Humidity9am   Humidity3pm  \\\ncount   97988.000000  97988.000000  97988.000000  97988.000000  97988.000000   \nmean        0.265107      0.108395      0.215668      0.686309      0.514693   \nstd         0.102420      0.068800      0.101424      0.189008      0.206376   \nmin         0.000000      0.000000      0.000000      0.000000      0.000000   \n25%         0.193798      0.053846      0.149425      0.570000      0.370000   \n50%         0.255814      0.100000      0.218391      0.690000      0.520000   \n75%         0.310078      0.146154      0.275862      0.830000      0.650000   \nmax         1.000000      0.669231      1.000000      1.000000      1.000000   \n\n        Pressure9am   Pressure3pm      Cloud9am      Cloud3pm       Temp9am  \\\ncount  97988.000000  97988.000000  97988.000000  97988.000000  97988.000000   \nmean       0.612014      0.608705      0.483192      0.493693      0.507089   \nstd        0.111335      0.106611      0.255486      0.238028      0.134722   \nmin        0.000000      0.030400      0.000000      0.000000      0.027426   \n25%        0.543802      0.540800      0.333333      0.333333      0.409283   \n50%        0.614125      0.610527      0.492351      0.499917      0.502110   \n75%        0.682645      0.675200      0.666667      0.666667      0.601266   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n            Temp3pm  \ncount  97988.000000  \nmean       0.517103  \nstd        0.130726  \nmin        0.005758  \n25%        0.422265  \n50%        0.506718  \n75%        0.604607  \nmax        0.988484  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustSpeed</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n      <td>97988.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.483689</td>\n      <td>0.525947</td>\n      <td>0.006396</td>\n      <td>0.036949</td>\n      <td>0.525366</td>\n      <td>0.265107</td>\n      <td>0.108395</td>\n      <td>0.215668</td>\n      <td>0.686309</td>\n      <td>0.514693</td>\n      <td>0.612014</td>\n      <td>0.608705</td>\n      <td>0.483192</td>\n      <td>0.493693</td>\n      <td>0.507089</td>\n      <td>0.517103</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.149458</td>\n      <td>0.131904</td>\n      <td>0.022962</td>\n      <td>0.021628</td>\n      <td>0.200931</td>\n      <td>0.102420</td>\n      <td>0.068800</td>\n      <td>0.101424</td>\n      <td>0.189008</td>\n      <td>0.206376</td>\n      <td>0.111335</td>\n      <td>0.106611</td>\n      <td>0.255486</td>\n      <td>0.238028</td>\n      <td>0.134722</td>\n      <td>0.130726</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.013233</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.030400</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.027426</td>\n      <td>0.005758</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.377358</td>\n      <td>0.429112</td>\n      <td>0.000000</td>\n      <td>0.026207</td>\n      <td>0.517241</td>\n      <td>0.193798</td>\n      <td>0.053846</td>\n      <td>0.149425</td>\n      <td>0.570000</td>\n      <td>0.370000</td>\n      <td>0.543802</td>\n      <td>0.540800</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.409283</td>\n      <td>0.422265</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.478774</td>\n      <td>0.514178</td>\n      <td>0.000000</td>\n      <td>0.037741</td>\n      <td>0.526244</td>\n      <td>0.255814</td>\n      <td>0.100000</td>\n      <td>0.218391</td>\n      <td>0.690000</td>\n      <td>0.520000</td>\n      <td>0.614125</td>\n      <td>0.610527</td>\n      <td>0.492351</td>\n      <td>0.499917</td>\n      <td>0.502110</td>\n      <td>0.506718</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.591981</td>\n      <td>0.618147</td>\n      <td>0.002156</td>\n      <td>0.038621</td>\n      <td>0.634483</td>\n      <td>0.310078</td>\n      <td>0.146154</td>\n      <td>0.275862</td>\n      <td>0.830000</td>\n      <td>0.650000</td>\n      <td>0.682645</td>\n      <td>0.675200</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.601266</td>\n      <td>0.604607</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.568276</td>\n      <td>0.986207</td>\n      <td>1.000000</td>\n      <td>0.669231</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.988484</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "training_x[numeric_cols].describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoding Categorical Data\n",
    "Similar to Linear Regression, one of the easiest way to use categorical data in regression is by dummy variables. Hence need to encode them:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "[array(['Adelaide', 'Albany', 'Albury', 'AliceSprings', 'BadgerysCreek',\n        'Ballarat', 'Bendigo', 'Brisbane', 'Cairns', 'Canberra', 'Cobar',\n        'CoffsHarbour', 'Dartmoor', 'Darwin', 'GoldCoast', 'Hobart',\n        'Katherine', 'Launceston', 'Melbourne', 'MelbourneAirport',\n        'Mildura', 'Moree', 'MountGambier', 'MountGinini', 'Newcastle',\n        'Nhil', 'NorahHead', 'NorfolkIsland', 'Nuriootpa', 'PearceRAAF',\n        'Penrith', 'Perth', 'PerthAirport', 'Portland', 'Richmond', 'Sale',\n        'SalmonGums', 'Sydney', 'SydneyAirport', 'Townsville',\n        'Tuggeranong', 'Uluru', 'WaggaWagga', 'Walpole', 'Watsonia',\n        'Williamtown', 'Witchcliffe', 'Wollongong', 'Woomera'],\n       dtype=object),\n array(['E', 'ENE', 'ESE', 'N', 'NE', 'NNE', 'NNW', 'NW', 'S', 'SE', 'SSE',\n        'SSW', 'SW', 'W', 'WNW', 'WSW', nan], dtype=object),\n array(['E', 'ENE', 'ESE', 'N', 'NE', 'NNE', 'NNW', 'NW', 'S', 'SE', 'SSE',\n        'SSW', 'SW', 'W', 'WNW', 'WSW', nan], dtype=object),\n array(['E', 'ENE', 'ESE', 'N', 'NE', 'NNE', 'NNW', 'NW', 'S', 'SE', 'SSE',\n        'SSW', 'SW', 'W', 'WNW', 'WSW', nan], dtype=object),\n array(['No', 'Yes'], dtype=object)]"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(raw_df[categorical_cols])\n",
    "encoder.categories_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then generate column names for each individual category:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "encoded_cols = list(encoder.get_feature_names(categorical_cols))\n",
    "\n",
    "training_x[encoded_cols] = encoder.transform(training_x[categorical_cols])\n",
    "validating_x[encoded_cols] = encoder.transform(validating_x[categorical_cols])\n",
    "testing_x[encoded_cols] = encoder.transform(testing_x[categorical_cols])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "       Location   MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  \\\n2498     Albury  0.681604  0.801512  0.000000     0.037741  0.526244   \n2499     Albury  0.693396  0.725898  0.001078     0.037741  0.526244   \n2500     Albury  0.634434  0.527410  0.005930     0.037741  0.526244   \n2501     Albury  0.608491  0.538752  0.042049     0.037741  0.526244   \n2502     Albury  0.566038  0.523629  0.018329     0.037741  0.526244   \n...         ...       ...       ...       ...          ...       ...   \n145454    Uluru  0.283019  0.502836  0.000000     0.037741  0.526244   \n145455    Uluru  0.266509  0.533081  0.000000     0.037741  0.526244   \n145456    Uluru  0.285377  0.568998  0.000000     0.037741  0.526244   \n145457    Uluru  0.327830  0.599244  0.000000     0.037741  0.526244   \n145458    Uluru  0.384434  0.601134  0.000000     0.037741  0.526244   \n\n       WindGustDir  WindGustSpeed WindDir9am WindDir3pm  ...  WindDir3pm_SE  \\\n2498           ENE       0.372093        NaN        ESE  ...            0.0   \n2499           SSE       0.341085        SSE         SE  ...            1.0   \n2500           ENE       0.325581        ESE        ENE  ...            0.0   \n2501           SSE       0.255814         SE        SSE  ...            0.0   \n2502           ENE       0.193798         SE        SSE  ...            0.0   \n...            ...            ...        ...        ...  ...            ...   \n145454           E       0.193798        ESE          E  ...            0.0   \n145455           E       0.193798         SE        ENE  ...            0.0   \n145456         NNW       0.124031         SE          N  ...            0.0   \n145457           N       0.240310         SE        WNW  ...            0.0   \n145458          SE       0.170543        SSE          N  ...            0.0   \n\n        WindDir3pm_SSE  WindDir3pm_SSW  WindDir3pm_SW  WindDir3pm_W  \\\n2498               0.0             0.0            0.0           0.0   \n2499               0.0             0.0            0.0           0.0   \n2500               0.0             0.0            0.0           0.0   \n2501               1.0             0.0            0.0           0.0   \n2502               1.0             0.0            0.0           0.0   \n...                ...             ...            ...           ...   \n145454             0.0             0.0            0.0           0.0   \n145455             0.0             0.0            0.0           0.0   \n145456             0.0             0.0            0.0           0.0   \n145457             0.0             0.0            0.0           0.0   \n145458             0.0             0.0            0.0           0.0   \n\n        WindDir3pm_WNW  WindDir3pm_WSW  WindDir3pm_nan  RainToday_No  \\\n2498               0.0             0.0             0.0           1.0   \n2499               0.0             0.0             0.0           1.0   \n2500               0.0             0.0             0.0           0.0   \n2501               0.0             0.0             0.0           0.0   \n2502               0.0             0.0             0.0           0.0   \n...                ...             ...             ...           ...   \n145454             0.0             0.0             0.0           1.0   \n145455             0.0             0.0             0.0           1.0   \n145456             0.0             0.0             0.0           1.0   \n145457             1.0             0.0             0.0           1.0   \n145458             0.0             0.0             0.0           1.0   \n\n        RainToday_Yes  \n2498              0.0  \n2499              0.0  \n2500              1.0  \n2501              1.0  \n2502              1.0  \n...               ...  \n145454            0.0  \n145455            0.0  \n145456            0.0  \n145457            0.0  \n145458            0.0  \n\n[25710 rows x 123 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Location</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>WindDir3pm</th>\n      <th>...</th>\n      <th>WindDir3pm_SE</th>\n      <th>WindDir3pm_SSE</th>\n      <th>WindDir3pm_SSW</th>\n      <th>WindDir3pm_SW</th>\n      <th>WindDir3pm_W</th>\n      <th>WindDir3pm_WNW</th>\n      <th>WindDir3pm_WSW</th>\n      <th>WindDir3pm_nan</th>\n      <th>RainToday_No</th>\n      <th>RainToday_Yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2498</th>\n      <td>Albury</td>\n      <td>0.681604</td>\n      <td>0.801512</td>\n      <td>0.000000</td>\n      <td>0.037741</td>\n      <td>0.526244</td>\n      <td>ENE</td>\n      <td>0.372093</td>\n      <td>NaN</td>\n      <td>ESE</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>Albury</td>\n      <td>0.693396</td>\n      <td>0.725898</td>\n      <td>0.001078</td>\n      <td>0.037741</td>\n      <td>0.526244</td>\n      <td>SSE</td>\n      <td>0.341085</td>\n      <td>SSE</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2500</th>\n      <td>Albury</td>\n      <td>0.634434</td>\n      <td>0.527410</td>\n      <td>0.005930</td>\n      <td>0.037741</td>\n      <td>0.526244</td>\n      <td>ENE</td>\n      <td>0.325581</td>\n      <td>ESE</td>\n      <td>ENE</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2501</th>\n      <td>Albury</td>\n      <td>0.608491</td>\n      <td>0.538752</td>\n      <td>0.042049</td>\n      <td>0.037741</td>\n      <td>0.526244</td>\n      <td>SSE</td>\n      <td>0.255814</td>\n      <td>SE</td>\n      <td>SSE</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2502</th>\n      <td>Albury</td>\n      <td>0.566038</td>\n      <td>0.523629</td>\n      <td>0.018329</td>\n      <td>0.037741</td>\n      <td>0.526244</td>\n      <td>ENE</td>\n      <td>0.193798</td>\n      <td>SE</td>\n      <td>SSE</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145454</th>\n      <td>Uluru</td>\n      <td>0.283019</td>\n      <td>0.502836</td>\n      <td>0.000000</td>\n      <td>0.037741</td>\n      <td>0.526244</td>\n      <td>E</td>\n      <td>0.193798</td>\n      <td>ESE</td>\n      <td>E</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>145455</th>\n      <td>Uluru</td>\n      <td>0.266509</td>\n      <td>0.533081</td>\n      <td>0.000000</td>\n      <td>0.037741</td>\n      <td>0.526244</td>\n      <td>E</td>\n      <td>0.193798</td>\n      <td>SE</td>\n      <td>ENE</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>145456</th>\n      <td>Uluru</td>\n      <td>0.285377</td>\n      <td>0.568998</td>\n      <td>0.000000</td>\n      <td>0.037741</td>\n      <td>0.526244</td>\n      <td>NNW</td>\n      <td>0.124031</td>\n      <td>SE</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>145457</th>\n      <td>Uluru</td>\n      <td>0.327830</td>\n      <td>0.599244</td>\n      <td>0.000000</td>\n      <td>0.037741</td>\n      <td>0.526244</td>\n      <td>N</td>\n      <td>0.240310</td>\n      <td>SE</td>\n      <td>WNW</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>145458</th>\n      <td>Uluru</td>\n      <td>0.384434</td>\n      <td>0.601134</td>\n      <td>0.000000</td>\n      <td>0.037741</td>\n      <td>0.526244</td>\n      <td>SE</td>\n      <td>0.170543</td>\n      <td>SSE</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25710 rows × 123 columns</p>\n</div>"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "testing_x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Data\n",
    "Since dataset is large, it would be better to save it on disk:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "# !pip install pyarrow --quiet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "training_x.to_parquet('training_x.parquet')\n",
    "validating_x.to_parquet('validating_x.parquet')\n",
    "testing_x.to_parquet('testing_x.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pd.DataFrame(training_y).to_parquet('training_y.parquet')\n",
    "pd.DataFrame(validating_y).to_parquet('validating_y.parquet')\n",
    "pd.DataFrame(testing_y).to_parquet('testing_y.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then Dataframe can be loaded by:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 141 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "training_x = pd.read_parquet('training_x.parquet')\n",
    "validating_x = pd.read_parquet('validating_x.parquet')\n",
    "testing_x = pd.read_parquet('testing_x.parquet')\n",
    "\n",
    "training_y = pd.read_parquet('training_y.parquet')[y_col]\n",
    "validating_y = pd.read_parquet('validating_y.parquet')[y_col]\n",
    "testing_y = pd.read_parquet('testing_y.parquet')[y_col]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Logistic Regression Model\n",
    "- Take linear combination\n",
    "- apply sigmoid function to result so that it is within 0 to 1\n",
    "- represent probability\n",
    "- use cross entropy loss function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
